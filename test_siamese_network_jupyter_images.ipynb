{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from test_helper import *\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import os \n",
    "import textwrap as tw\n",
    "from PIL import Image\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 128, 3)\n",
      "(None, 256, 128, 256)\n",
      "(None, 128, 64, 256)\n",
      "(None, 128, 64, 128)\n",
      "(None, 64, 32, 128)\n",
      "(None, 64, 32, 64)\n",
      "(None, 32, 16, 64)\n",
      "(None, 32, 16, 32)\n",
      "(None, 16, 8, 32)\n",
      "(None, 4096)\n",
      "(None, 4096)\n",
      "(None, 256, 128, 3)\n",
      "(None, 256, 128, 256)\n",
      "(None, 128, 64, 256)\n",
      "(None, 128, 64, 128)\n",
      "(None, 64, 32, 128)\n",
      "(None, 64, 32, 64)\n",
      "(None, 32, 16, 64)\n",
      "(None, 32, 16, 32)\n",
      "(None, 16, 8, 32)\n",
      "(None, 4096)\n",
      "(None, 4096)\n"
     ]
    }
   ],
   "source": [
    "left_input_im = tf.compat.v1.placeholder(tf.float32, [None, 256, 128, 3], 'left_input_im')\n",
    "right_input_im = tf.compat.v1.placeholder(tf.float32, [None, 256, 128, 3], 'right_input_im')\n",
    "left_label = tf.compat.v1.placeholder(tf.float32, [None, ], 'left_label')\n",
    "right_label = tf.compat.v1.placeholder(tf.float32, [None, ], 'right_label')\n",
    "\n",
    "# print(np.shape(left_input_im), np.shape(right_input_im))\n",
    "logits, model_left, model_right = inference(left_input_im, right_input_im)\n",
    "global_step = tf.compat.v1.Variable(0, trainable=False)\n",
    "global_init = tf.compat.v1.variables_initializer(tf.compat.v1.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 18:19:01.191549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: model_siamese/model.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sess\u001b[38;5;241m.\u001b[39mrun(global_init)\n\u001b[1;32m      4\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mget_checkpoint_state(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_siamese/model.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m im2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/training/saver.py:1414\u001b[0m, in \u001b[0;36mSaver.restore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1412\u001b[0m checkpoint_prefix \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(save_path)\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_management\u001b[38;5;241m.\u001b[39mcheckpoint_exists_internal(checkpoint_prefix):\n\u001b[0;32m-> 1414\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe passed save_path is not a valid checkpoint: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1415\u001b[0m                    checkpoint_prefix)\n\u001b[1;32m   1417\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoring parameters from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, checkpoint_prefix)\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: model_siamese/model.ckpt"
     ]
    }
   ],
   "source": [
    "saver = tf.compat.v1.train.Saver()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(global_init)\n",
    "    ckpt = tf.train.get_checkpoint_state(\"model\")\n",
    "    saver.restore(sess, \"model_siamese/model.ckpt\")\n",
    "\n",
    "    for im1 in range(1,8):\n",
    "        for im2 in range(1,8):\n",
    "\n",
    "\n",
    "            img = Image.open(str(im1) + '.jpg')\n",
    "            img = np.array(img)[np.newaxis,:,:,:]\n",
    "            # img2 = img\n",
    "            img2 = Image.open(str(im2) + '.jpg')\n",
    "            img2 = np.array(img2)[np.newaxis,:,:,:]\n",
    "\n",
    "\n",
    "            my_logits, model_lf, model_rg = sess.run([logits, model_left, model_right], \\\n",
    "                                                     feed_dict={left_input_im:img, right_input_im:img2})\n",
    "            \n",
    "            lft = np.array(model_lf[0])\n",
    "            rgt = np.array(model_rg[0])\n",
    "            l = lft - rgt\n",
    "\n",
    "            distance = np.sqrt(np.sum((l) ** 2))\n",
    "            similarity = my_logits * np.square(distance)  # keep the similar label (1) close to each other\n",
    "            dissimilarity = (1 - np.array(my_logits[0])) * np.square(np.max((0.5 - distance),\n",
    "                                                           0))  # give penalty to dissimilar label if the distance is bigger than margin\n",
    "            similarity_loss = np.mean(dissimilarity + similarity) / 2\n",
    "\n",
    "            dist = cdist(model_lf, model_rg, 'cosine')\n",
    "            euc = np.linalg.norm(model_lf - model_rg)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.title(('Similarity: %f, Dissimilarity: %f\\nEuclidean Dist: %f, Logits: %f' % (similarity, dissimilarity, euc, my_logits)), loc='center')\n",
    "            if my_logits > 0.0:\n",
    "                textstr = 'Similar ' + str(my_logits)\n",
    "                props = dict(boxstyle='round', facecolor='green', alpha=0.5)\n",
    "                fig_txt = tw.fill(tw.dedent(textstr), width=80)\n",
    "                plt.figtext(0.51, 0.05, fig_txt, horizontalalignment='center',\n",
    "                            fontsize=12, multialignment='center',\n",
    "                            bbox=dict(boxstyle=\"round\", facecolor='green',\n",
    "                                      ec=\"0.5\", pad=0.5, alpha=1), fontweight='bold')\n",
    "            else:\n",
    "                textstr = 'Dissimilar ' + str(my_logits)\n",
    "                props = dict(boxstyle='round', facecolor='red', alpha=0.5)\n",
    "                fig_txt = tw.fill(tw.dedent(textstr), width=80)\n",
    "                plt.figtext(0.51, 0.05, fig_txt, horizontalalignment='center',\n",
    "                            fontsize=12, multialignment='center',\n",
    "                            bbox=dict(boxstyle=\"round\", facecolor='red',\n",
    "                                      ec=\"0.5\", pad=0.5, alpha=1), fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "            plt.axis('off')\n",
    "            ax1 = fig.add_subplot(1, 2, 1)\n",
    "            l_im = np.array(img)[0]\n",
    "            ax1.imshow(l_im)\n",
    "            ax1.axis('off')\n",
    "            ax2 = fig.add_subplot(1, 2, 2)\n",
    "            r_im = np.array(img2)[0]\n",
    "            ax2.imshow(r_im)\n",
    "            ax2.axis('off')\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
